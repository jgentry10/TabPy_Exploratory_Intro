{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tabpy_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loans have the following purposes:\n",
      " ['debt_consolidation' 'other' 'car' 'moving' 'credit_card' 'vacation'\n",
      " 'major_purchase' 'small_business' 'house' 'wedding' 'medical'\n",
      " 'home_improvement']\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('LoanStatsFilter.csv')\n",
    "train = train[train.inactive_loans == 1]\n",
    "print('Loans have the following purposes:\\n',train['purpose'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train.iloc[:,1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = preprocessing.LabelEncoder()\n",
    "enc2 = preprocessing.LabelEncoder()\n",
    "train['grade'] = enc.fit_transform(train['grade'])\n",
    "train['purpose'] = enc2.fit_transform(train['purpose'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 122603 entries, 0 to 122602\n",
      "Data columns (total 8 columns):\n",
      "id                122603 non-null int64\n",
      "grade             122603 non-null int64\n",
      "annual_inc        122603 non-null int64\n",
      "sub_grade_num     122603 non-null float64\n",
      "purpose           122603 non-null int64\n",
      "dti               122603 non-null float64\n",
      "bad_loans         122603 non-null int64\n",
      "inactive_loans    122603 non-null int64\n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 8.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   grade  annual_inc  sub_grade_num  purpose    dti\n",
      "0      6        1896            0.6        2  18.99\n",
      "1      1        2000            0.4        8   0.00\n",
      "2      4        3000            0.4        0  10.40\n",
      "3      0        3300            0.6        8   0.00\n",
      "4      0        3500            0.4        8   5.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Separate the data into the class labels y and the feature variables X.\n",
    "targets = train['bad_loans']\n",
    "y = np.array(train['bad_loans']).astype(int)\n",
    "X = train.ix[:,1:6]\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0.0, 1.0))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(500,500,100), activation='relu', solver='adam', alpha=1e-5,\n",
    "                                         batch_size='auto', learning_rate='constant', learning_rate_init=0.0001,\n",
    "                                         power_t=0.5, max_iter=10, shuffle=True, random_state=None,\n",
    "                                         tol=0.00001, verbose=True, warm_start=False, momentum=0.9,\n",
    "                                         nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1,\n",
    "                                         beta_1=0.9, beta_2=0.999, epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(predictions[:10])\n",
    "probs = model.predict_proba(X_test)\n",
    "print(probs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.2\n",
    "threshold_preds = []\n",
    "for i in range(len(probs)):\n",
    "    if probs[i][1] >= threshold:\n",
    "        threshold_preds.append(1)\n",
    "    else:\n",
    "        threshold_preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, threshold_preds)\n",
    "print(\"The model produced {0}% accurate predictions.\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, threshold_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, threshold_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loanclassifierfull(_arg1, _arg2, _arg3, _arg4, _arg5):\n",
    "    from pandas import DataFrame\n",
    "\n",
    "    # Load data from tableau (brought in as lists) into a dictionary\n",
    "    # The columns get sorted alphabetically in this constructor\n",
    "    # Adding the numbers sorts them correctly\n",
    "    d = {'1-grade': _arg1, '2-income': _arg2, '3-sub_grade_num': _arg3, '4-purpose': _arg4, '5-dti': _arg5}\n",
    "    \n",
    "    # Convert the dictionary to a Pandas Dataframe\n",
    "    df = DataFrame(data=d)\n",
    "\n",
    "    # Transform categorical variables into numerical/continuous features\n",
    "    df['1-grade'] = enc.transform(df['1-grade'])\n",
    "    df['4-purpose'] = enc2.transform(df['4-purpose'])\n",
    "    print(df.head())\n",
    "\n",
    "    # We need to scale the inputs to the Model or it will be off\n",
    "    # The scaler, since it's saved in the code, will be pickled automatically by TabPy and available for reuse\n",
    "    # This should also be the case for the feature encoder above\n",
    "    df = scaler.transform(df)\n",
    "\n",
    "    # Use the loaded model to develop predictions for the new data from Tableau\n",
    "    probs = model.predict_proba(df)\n",
    "    return [loan[1] for loan in probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_probs =loanclassifierfull(test.iloc[:,0],test.iloc[:,1],test.iloc[:,2],test.iloc[:,3],test.iloc[:,4])\n",
    "print('Calc Results Come After This')\n",
    "print(func_probs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tabpy_client.Client('http://localhost:9004')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.deploy('loanclassifierfull', loanclassifierfull,\n",
    "              'Returns the probablility that a loan will result in a bad loan based on its Grade, Income, '\n",
    "              'SubGradeNum, Purpose, and DTI', override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
